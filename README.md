# Mini Project 5: CNN Image Classifier - Chest X-Ray Pneumonia Detection

**Course:** COMP 9130 - Applied Artificial Intelligence  
**Date:** February 14, 2026

## üìã Project Overview

This project implements a Convolutional Neural Network (CNN) for binary classification of chest X-ray images to detect pneumonia. The project includes:

- **Baseline CNN Model** - Standard architecture without data augmentation
- **Improved CNN Model** - Enhanced with data augmentation techniques
- **Architecture Experiments** - Exploration of alternative designs (bonus work)
- **Comprehensive Analysis** - Data exploration, model comparison, and performance evaluation

### üéØ Final Results

| Model | Architecture | Augmentation | Test Accuracy | Improvement  |
|-------|-------------|--------------|---------------|--------------|
| **Baseline** | 3 conv blocks, Flatten | No | 75.32%        | -            |
| **Improved (V3)** | 3 conv blocks, Flatten | Yes | **74.84%**    | **-0.48%** ‚úÖ |

**Final Result:** 74.84% test accuracy with a -0.48% change over baseline  (but a near-perfect 99.74% Recall).

---

## üìÅ Project Structure

```
mini-project-5/
‚îú‚îÄ‚îÄ README.md                    # This file
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ data/                        # Dataset (not included in repo)
‚îÇ   ‚îî‚îÄ‚îÄ chest_xray/
‚îÇ       ‚îî‚îÄ‚îÄ train/
‚îÇ           ‚îú‚îÄ‚îÄ NORMAL/
‚îÇ           ‚îî‚îÄ‚îÄ PNEUMONIA/
‚îú‚îÄ‚îÄ notebooks/                          # Jupyter notebooks (primary work)
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploration.ipynb            # Data exploration and analysis
‚îÇ   ‚îú‚îÄ‚îÄ 02_baseline_model.ipynb         # Baseline CNN (no augmentation)
‚îÇ   ‚îú‚îÄ‚îÄ 03_improved_model_v3.ipynb      # Improved CNN (with augmentation)
‚îÇ   ‚îî‚îÄ‚îÄ experiments/                    # Optional experiments folder
‚îÇ       ‚îú‚îÄ‚îÄ improved_model_v1.ipynb     # Failed experiment
‚îÇ       ‚îî‚îÄ‚îÄ improved_model_v2.ipynb     # Failed experiment
‚îú‚îÄ‚îÄ src/                           # Modular Python code (optional)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ models.py                  # Model architectures
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py             # Data loading and augmentation
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                   # Visualization and evaluation utilities
‚îú‚îÄ‚îÄ models/                        # Final models only
‚îÇ   ‚îú‚îÄ‚îÄ baseline_model_final.keras
‚îÇ   ‚îî‚îÄ‚îÄ improved_v3_final.keras
‚îî‚îÄ‚îÄ results/                       # Outputs (figures, metrics, reports)
    ‚îú‚îÄ‚îÄ baseline_confusion_matrix_test.png
    ‚îú‚îÄ‚îÄ improved_v3_confusion_matrix.png
    ‚îú‚îÄ‚îÄ model_comparison.csv
    ‚îî‚îÄ‚îÄ ...
```

---

## üöÄ Quick Start

### Prerequisites

- Python 3.11
- TensorFlow 2.15.0
- Jupyter Notebook
- At least 8GB RAM (16GB recommended)
- GPU optional (Apple Metal / CUDA supported)

### Installation

1. **Clone the repository** (or download the project files)
   ```bash
   cd mini-project-5
   ```

2. **Create a virtual environment**
   ```bash
   python3.11 -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Download the dataset**
   - Dataset: [Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
   - Extract to `data/chest_xray/`

### Running the Project

**Option 1: Run Jupyter Notebooks (Recommended)**

All analysis and model training is fully documented in notebooks:

```bash
jupyter notebook
```

Then open notebooks in order:

1. **`exploration.ipynb`** - Data exploration and analysis
   - Dataset statistics and visualization
   - Class distribution analysis
   - Image property examination
   
2. **`baseline_model.ipynb`** - Baseline CNN model
   - 3 convolutional blocks
   - No data augmentation
   - Result: 75.32% test accuracy
   
3. **`improved_model_v3.ipynb`** - Improved CNN model
   - Same architecture as baseline
   - Light data augmentation added
   - Result: 74.84% test accuracy ‚úÖ

4. **Optional:** Architecture experiment notebooks (V1, V2) for bonus analysis

**Option 2: Use Modular Code (Optional)**

The `src/` folder contains modular Python code extracted from notebooks:

```python
from src.models import build_baseline_cnn, build_improved_cnn_v3
from src.data_loader import load_images_from_directory, create_augmentation_generator
from src.utils import evaluate_model, plot_training_history

# Load data
X_train, y_train, _ = load_images_from_directory('../data/chest_xray/train')

# Build and train model
model = build_improved_cnn_v3()
history = model.fit(X_train, y_train, epochs=25, ...)

# Evaluate
results = evaluate_model(model, X_test, y_test)
```

---

## üìä Dataset Information

**Source:** [Kaggle - Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)

**Statistics:**
- **Training:** 5,216 images (1,341 NORMAL, 3,875 PNEUMONIA)
- **Validation:** 16 images (8 NORMAL, 8 PNEUMONIA) ‚ö†Ô∏è Too small
- **Test:** 624 images (234 NORMAL, 390 PNEUMONIA)
- **Total:** 5,856 chest X-ray images

**Key Findings:**
- **Class Imbalance:** 2.89:1 ratio (Pneumonia:Normal) in training set
- **Image Sizes:** Highly variable (232-2,625 pixels)
- **Format:** Grayscale X-ray images saved as RGB (3 channels)

**Preprocessing Applied:**
- Resized to 224√ó224 pixels
- Converted to grayscale (1 channel)
- Normalized to [0, 1] range
- Created new 80/20 train/validation split from training data

---

## Dataset Setup

The dataset is NOT included in this repository due to size constraints (~6GB).

**To download the dataset:**
1. See detailed instructions in `data/DATA_INSTRUCTIONS.txt`
2. Quick link: [Kaggle Dataset](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
3. Extract to `data/chest_xray/`

After downloading, your `data/` folder structure should match the layout in `DATA_INSTRUCTIONS.txt`.

---

## üß† Model Architecture & Performance

### Baseline CNN

* **Architecture:** 3 Convolutional blocks with BatchNormalization and ReLU activation, followed by a Dropout (0.5) layer.
* **Training:** Standard training without data augmentation.
* **Test Performance:** 75.32% Accuracy , 99.49% Recall.
* **Issue:** High False Positive rate (152 normal cases misclassified as pneumonia).

### Improved CNN (V3)

* **Architecture:** Identical to the baseline to isolate the impact of data augmentation. 
* **Data Augmentation:** Applied light, medical-safe transformations (rotation ¬±10¬∞, shifts ¬±8%, and zoom 92-108%). 
* **Test Performance:** 74.84% Accuracy , 99.74% Recall.
* **Improvement:** Successfully reduced False Negatives to just one single case in the test set.

---

### üî¨ Experimental Work (Bonus)

As part of the bonus architecture exploration, we experimented with:

* **Experiment 1 (V1):** GlobalAveragePooling + Heavy Regularization resulted in a 43.27% test accuracy. 
* **Experiment 2 (V2):** Adjusted Regularization only slightly improved performance to 62.50% test accuracy. 
* **Key Learning:** Architectural complexity does not guarantee better results; keeping the proven baseline and focusing on data quality (augmentation) was more effective for this specific domain

---

## üìà Results Summary

### Model Comparison

| Metric | Baseline | Improved (V3) | Change           |
|--------|----------|---------------|------------------|
| **Val Accuracy** | 97.80%   | 96.46%        | -1.34%           |
| **Test Accuracy** | 75.32%   | **74.84%**    | **--0.48%** ‚úÖ    |
| **Test Precision** | 71.85%   | 71.38%        | -0.47%           |
| **Test Recall** | 99.49%   | 99.74%        | +0.25%           |
| **Test F1-Score** | 0.8344   | 0.8321        | -0.23%           |
| **False Positives** | 2        | 1             | -1 (Reduction) ‚úÖ |

### Confusion Matrix Analysis

**Baseline Model:**
```
              Predicted
              NORMAL  PNEUMONIA
Actual NORMAL    83      152     ‚Üê High false positives (65%)
       PNEUMONIA  2      388     ‚Üê Low false negatives
```

**Improved Model (V3):**
```
              Predicted
              NORMAL  PNEUMONIA
Actual NORMAL   78     156    ‚Üê Significant "cautious" bias
       PNEUMONIA  1    389    ‚Üê Near-perfect Recall (99.74%)
```

### Key Insights

1. **Clinical Sensitivity Over Accuracy:** In pneumonia detection, a False Negative (missed diagnosis) is significantly more dangerous than a False Positive. 
2. **Trade-off in Specificity:** By increasing model sensitivity to catch 99.74% of cases, the model became more aggressive, leading to a high False Positive rate (156 cases). 
3. **The "Simpler is Better" Principle:** The failed experiments in V1 and V2 demonstrated that a simple, well-tuned 3-block CNN often generalizes better on small medical datasets than complex, over-regularized architectures.

---

## üõ†Ô∏è Technical Details

### Training Configuration

**Baseline:**
- Optimizer: Adam (lr=0.001)
- Loss: Binary Crossentropy
- Batch Size: 32
- Epochs: 25 (early stopping patience=5)
- Class Weights: 1.94 (NORMAL), 0.67 (PNEUMONIA)

**Improved (V3):**
- Same configuration as baseline
- Added: Data augmentation during training
- Augmentation parameters: Conservative (medical imaging safe)

### Evaluation Metrics

We tracked multiple metrics to ensure balanced performance:

- **Accuracy:** Overall correctness
- **Precision:** Of predicted pneumonia cases, how many are correct?
- **Recall:** Of actual pneumonia cases, how many did we catch?
- **F1-Score:** Harmonic mean of precision and recall

**Clinical Priority:** High recall (don't miss pneumonia cases) while maintaining reasonable precision (avoid false alarms).

---

## üìÅ Files Description

### Notebooks
- `exploration.ipynb` - Data analysis, visualization, insights
- `baseline_model.ipynb` - Baseline CNN training and evaluation
- `improved_model_v3.ipynb` - Improved CNN with augmentation
- `improved_model.ipynb` - Architecture experiment V1 (bonus)
- `improved_model_v2.ipynb` - Architecture experiment V2 (bonus)

### Source Code (Optional)
- `src/models.py` - CNN architecture definitions
- `src/data_loader.py` - Data loading and augmentation
- `src/utils.py` - Visualization and evaluation utilities

### Outputs
- `models/*.keras` - Saved model weights
- `results/*.png` - Confusion matrices, training curves, sample images
- `results/*.csv` - Metrics and comparison tables

---

## üéì Learning Outcomes

### Technical Skills Demonstrated

1. **CNN Architecture Design**
   - Convolutional layers with proper padding
   - Batch normalization for training stability
   - Dropout for regularization

2. **Medical Imaging Best Practices**
   - Conservative augmentation (no anatomical flips)
   - Grayscale handling
   - Class imbalance mitigation

3. **Model Evaluation**
   - Multiple metrics (accuracy, precision, recall, F1)
   - Confusion matrix analysis
   - Generalization assessment (train vs. val vs. test)

4. **Experimental Methodology**
   - Baseline establishment
   - Controlled experiments (V1, V2, V3)
   - Failure analysis and iteration

### Key Takeaways

1. **Prioritize Clinical Safety over Raw Accuracy** ‚Äì While data augmentation led to a slight 0.48% decrease in overall test accuracy , it achieved a near-perfect Recall of 99.74%. In a medical context, reducing False Negatives to just 1 case is a more valuable outcome than a slightly higher accuracy score.
2. **Simpler Architectures Generalize Better** ‚Äì The 3-block baseline architecture proved more robust for this dataset than the more complex V1 and V2 experimental designs. Architectural complexity (like adding more layers or GlobalAveragePooling) often led to over-regularization and failed to learn the subtle features of X-ray images.
3. **Accuracy is a Misleading Metric for Imbalanced Data** ‚Äì With a class imbalance of 2.89:1 , high accuracy can be achieved by simply over-predicting the majority class. By using balanced class weights and focusing on the F1-Score and Recall, we ensured the model was truly learning to distinguish between healthy and infected lungs.
4. **Iterative Refinement through Failure** ‚Äì The project followed a rigorous scientific approach: the failures of the V1 (GlobalAveragePooling) and V2 (Heavy Regularization) experiments directly informed the "back-to-basics" strategy of V3. This demonstrated that light, domain-specific augmentation is more effective than deep architectural changes for small medical datasets.
---

## üöß Known Limitations

1. **Dataset Imbalance**
   - 2.89:1 ratio (Pneumonia:Normal)
   - Mitigated with class weights and augmentation

2. **Original Validation Set Too Small**
   - Only 16 images in original validation set
   - Created new 80/20 split from training data

3. **Generalization Concerns**
   - Dataset from single source
   - May not generalize to different X-ray equipment/protocols

4. **Computational Resources**
   - Training takes 15-30 minutes per model (CPU)
   - GPU recommended for faster iteration

---

## üìö References

1. **Dataset:**
   - Kermany, D., Zhang, K., & Goldbaum, M. (2018). Chest X-Ray Images (Pneumonia). Kaggle. 
   - https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia

2. **Architecture Inspiration:**
   - He, K., et al. (2016). Deep Residual Learning for Image Recognition
   - Simonyan, K., & Zisserman, A. (2014). Very Deep Convolutional Networks

3. **Medical Imaging ML:**
   - Rajpurkar, P., et al. (2017). CheXNet: Radiologist-Level Pneumonia Detection
   - Esteva, A., et al. (2019). A guide to deep learning in healthcare

4. **Data Augmentation:**
   - Shorten, C., & Khoshgoftaar, T. M. (2019). A survey on Image Data Augmentation
   - Perez, L., & Wang, J. (2017). The Effectiveness of Data Augmentation

---

## ü§ù Acknowledgments

- **Course Instructor:** COMP 9130 - Machine Learning
- **Dataset:** Kermany et al., Kaggle
- **Framework:** TensorFlow/Keras
- **Development Environment:** Python 3.11, Jupyter Notebook

---

## üìù License

This project is for educational purposes as part of COMP 9130 coursework.

---

## üîÑ Project Status

‚úÖ **Completed** - February 14, 2026

**Deliverables:**
- [x] Data exploration and analysis
- [x] Baseline CNN model (75.32% test accuracy)
- [x] Improved CNN model (74.84% test accuracy)
- [x] Architecture experiments (bonus work)
- [x] Comprehensive evaluation and comparison
- [x] Documentation and code organization

## Team Contributions

This project was a collaborative effort between two partners. Responsibilities were divided to ensure both technical implementation and comprehensive analysis were handled effectively.

---

### Binger Yu

#### Data Preprocessing & Implementation
- Developed the custom data loading pipeline  
- Implemented image normalization  
- Calculated class weights for imbalance handling

#### Model Development
- Built and trained the baseline CNN architecture from scratch to establish initial performance metrics

#### Experimental Iteration
- Conducted multiple architecture experiments:
  - Improved V1 (GlobalAveragePooling)
  - Improved V2 (Heavy Regularization)
- Explored performance boundaries across designs

#### Final Model Optimization
- Developed and optimized the **Improved V3 model**
- Implemented medical-safe data augmentation
- Achieved near-perfect recall of **99.74%**

#### Repository Management
- Set up and maintained the GitHub repository  
- Organized directory structure  
- Managed `.gitignore` files  
- Ensured reproducibility

#### Notebook Documentation
- Completed primary Jupyter notebooks:
  - exploration
  - baseline_model
  - improved_model_v3_enhanced
- Added detailed documentation and visualizations

#### Report Infrastructure
- Created the Overleaf project template to support collaborative report writing

---

### Savina Cai

#### Report Writing & Analysis
- Authored the complete **LaTeX report** (12 pages, 6 sections) based on experimental results and notebook outputs
- Wrote all report sections: Introduction, Methodology, Results, Discussion, Conclusion, and References

#### Introduction & Background Research
- Researched and wrote the clinical background on pneumonia detection and the role of deep learning in medical imaging
- Summarized the dataset characteristics, class imbalance issues, and project objectives

#### Methodology Documentation
- Documented the full data preprocessing pipeline (grayscale conversion, resizing, normalization, stratified splitting)
- Created detailed architecture tables for the baseline CNN (layer-by-layer parameter breakdown)
- Described the V3 augmentation strategy and justified the choice to disable flips for anatomical plausibility
- Summarized the V1 and V2 experimental failures and the lessons that informed the V3 approach

#### Results Compilation & Presentation
- Compiled and formatted all quantitative results into comparison tables (baseline vs. V3 across all metrics)
- Analyzed confusion matrices and computed clinical metrics (sensitivity, specificity, PPV, NPV, FPR, FNR)
- Documented the experimental architecture results (V1: 43.27%, V2: 62.50%) with context

#### Discussion & Critical Analysis
- Analyzed the clinical safety vs. raw accuracy trade-off and justified why V3 was selected despite lower accuracy
- Discussed the impact of data augmentation on generalization and the overfitting gap
- Provided critical analysis of the failed experiments (V1, V2) and the "simpler is better" principle for small medical datasets
- Examined the high false positive rate and its implications for clinical deployment

#### Conclusion & Future Work
- Summarized key findings and contributions of the project
- Proposed five directions for future work: transfer learning, larger datasets, threshold optimization, Grad-CAM visualization, and multi-class classification

#### References & Citations
- Curated 9 academic references including Kermany et al. (2018), CheXNet, and data augmentation surveys
- Ensured proper citation formatting throughout the report



---
